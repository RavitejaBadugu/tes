{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting transformers==4.6.1\n",
      "  Downloading transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 23.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from transformers==4.6.1) (2020.11.13)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from transformers==4.6.1) (1.18.5)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 71.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 82.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from transformers==4.6.1) (4.57.0)\n",
      "Requirement already satisfied: requests in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from transformers==4.6.1) (2.25.1)\n",
      "Requirement already satisfied: packaging in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from transformers==4.6.1) (20.9)\n",
      "Requirement already satisfied: importlib-metadata in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from transformers==4.6.1) (3.7.0)\n",
      "Requirement already satisfied: filelock in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from transformers==4.6.1) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from importlib-metadata->transformers==4.6.1) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from importlib-metadata->transformers==4.6.1) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from packaging->transformers==4.6.1) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.1) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.1) (2020.12.5)\n",
      "Requirement already satisfied: six in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers==4.6.1) (1.15.0)\n",
      "Requirement already satisfied: click in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers==4.6.1) (7.1.2)\n",
      "Requirement already satisfied: joblib in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers==4.6.1) (1.0.1)\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting tensorflow==2.4.1\n",
      "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 394.3 MB 5.7 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio~=1.32.0 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.32.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.13.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.3.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12.1)\n",
      "Requirement already satisfied: six~=1.15.0 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.15.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.2.0)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 94.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.36.2)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.10.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.5.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.4.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.15.2)\n",
      "Requirement already satisfied: gast==0.3.3 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (49.6.0.post20210108)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.33.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.4.0)\n",
      "Installing collected packages: numpy, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-serving-api 2.4.2 requires tensorflow<3,>=2.4.2, but you have tensorflow 2.4.1 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.19.5 tensorflow-2.4.1\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: tokenizers==0.10.3 in ./anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (0.10.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.6.1\n",
    "!pip install tensorflow==2.4.1\n",
    "!pip install tokenizers==0.10.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  tweet-sentiment-extraction.zip\n",
      "  inflating: sample_submission.csv   \n",
      "  inflating: test.csv                \n",
      "  inflating: train.csv               \n"
     ]
    }
   ],
   "source": [
    "!unzip tweet-sentiment-extraction.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:41.991248Z",
     "iopub.status.busy": "2021-08-31T07:48:41.990768Z",
     "iopub.status.idle": "2021-08-31T07:48:49.742885Z",
     "shell.execute_reply": "2021-08-31T07:48:49.741815Z",
     "shell.execute_reply.started": "2021-08-31T07:48:41.991163Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from transformers import TFBertModel,TFRobertaModel,RobertaTokenizer\n",
    "import tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:51.347489Z",
     "iopub.status.busy": "2021-08-31T07:48:51.347137Z",
     "iopub.status.idle": "2021-08-31T07:48:53.048748Z",
     "shell.execute_reply": "2021-08-31T07:48:53.047439Z",
     "shell.execute_reply.started": "2021-08-31T07:48:51.347457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-02 07:24:53--  https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.16.70\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.16.70|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 898823 (878K) [application/json]\n",
      "Saving to: ‘roberta-base-vocab.json’\n",
      "\n",
      "roberta-base-vocab. 100%[===================>] 877.76K   789KB/s    in 1.1s    \n",
      "\n",
      "2021-09-02 07:24:55 (789 KB/s) - ‘roberta-base-vocab.json’ saved [898823/898823]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:53.051985Z",
     "iopub.status.busy": "2021-08-31T07:48:53.051600Z",
     "iopub.status.idle": "2021-08-31T07:48:54.696722Z",
     "shell.execute_reply": "2021-08-31T07:48:54.695441Z",
     "shell.execute_reply.started": "2021-08-31T07:48:53.051912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-02 07:24:55--  https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.90.246\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.90.246|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 456318 (446K) [text/plain]\n",
      "Saving to: ‘roberta-base-merges.txt’\n",
      "\n",
      "roberta-base-merges 100%[===================>] 445.62K   597KB/s    in 0.7s    \n",
      "\n",
      "2021-09-02 07:24:57 (597 KB/s) - ‘roberta-base-merges.txt’ saved [456318/456318]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:54.795705Z",
     "iopub.status.busy": "2021-08-31T07:48:54.795177Z",
     "iopub.status.idle": "2021-08-31T07:48:54.915416Z",
     "shell.execute_reply": "2021-08-31T07:48:54.914046Z",
     "shell.execute_reply.started": "2021-08-31T07:48:54.795650Z"
    }
   },
   "outputs": [],
   "source": [
    "roberta_tokenizer=tokenizers.ByteLevelBPETokenizer('./roberta-base-vocab.json','./roberta-base-merges.txt',\n",
    "                                                  lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=roberta_tokenizer.encode('Hi! I am ec2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3592, 328, 939, 524, 20508, 176]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', '!', 'Ġi', 'Ġam', 'Ġec', '2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (2, 3), (3, 5), (5, 8), (8, 11), (11, 12)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:54.935128Z",
     "iopub.status.busy": "2021-08-31T07:48:54.934637Z",
     "iopub.status.idle": "2021-08-31T07:48:54.956796Z",
     "shell.execute_reply": "2021-08-31T07:48:54.955783Z",
     "shell.execute_reply.started": "2021-08-31T07:48:54.935064Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_roberta_data(text,tokenizer,sentiment,selected_text=None,max_len=512):\n",
    "    idx0=-1\n",
    "    idx1=-1\n",
    "    # for some sentences we have spaces at the begining and for some we don't have\n",
    "    text=' '.join(text.split())\n",
    "    sentiment=' '.join(sentiment.split())\n",
    "    if selected_text is not None:\n",
    "        selected_text=' '.join(selected_text.split())\n",
    "    #roberta requires the ' '+text\n",
    "    text=' '+text\n",
    "    sentiment=' '+sentiment\n",
    "    char_level_list=[0]*len(text)\n",
    "    senti_id=tokenizer.encode(sentiment).ids\n",
    "    senti_offset=tokenizer.encode(sentiment).offsets\n",
    "    token_ids=tokenizer.encode(text).ids\n",
    "    offsets=tokenizer.encode(text).offsets\n",
    "    if len(token_ids)>(max_len-5):\n",
    "        token_ids=[0]+token_ids[:(max_len-5)]+[2]+[2]+senti_id+[2]\n",
    "        offsets=[(-1,-1)]+offsets[:(max_len-5)]+[(-1,-1)]+[(-1,-1)]+senti_offset+[(-1,-1)]\n",
    "    else:\n",
    "        pad_len=max_len-len(token_ids)-5\n",
    "        token_ids=[0]+token_ids+[2]+[2]+senti_id+[2]+[1]*pad_len\n",
    "        offsets=[(-1,-1)]+offsets+[(-1,-1)]+[(-1,-1)]+senti_offset+[(-1,-1)]+[(-1,-1)]*pad_len\n",
    "    attention_mask=np.not_equal(1,token_ids).astype('int')\n",
    "    if selected_text is None:\n",
    "        return {'input_ids':token_ids,'attention_mask':attention_mask}\n",
    "    else:\n",
    "        text=' '.join(text.split())\n",
    "        sentiment=' '.join(sentiment.split())\n",
    "        for i,letter in enumerate(text):\n",
    "            if letter==selected_text[0]:\n",
    "                temp_idx0=i\n",
    "                temp_idx1=i+len(selected_text)\n",
    "                if text[temp_idx0:temp_idx1]==selected_text:\n",
    "                    idx0=temp_idx0\n",
    "                    idx1=temp_idx1-1\n",
    "                    break\n",
    "        if idx0!=-1 and idx1!=-1:\n",
    "            for j in range(idx0,idx1+1):\n",
    "                char_level_list[j]=1\n",
    "        target_idx=[0]*max_len\n",
    "        target_start=[0]*max_len\n",
    "        target_end=[0]*max_len\n",
    "        zz_counter=0\n",
    "        for i,(s,e) in enumerate(offsets):\n",
    "            if e!=-1:\n",
    "                if e==0:\n",
    "                    if char_level_list[s]>0:\n",
    "                        target_idx[i]=1\n",
    "                else:\n",
    "                    if sum(char_level_list[s:e])>0:\n",
    "                        target_idx[i]=1\n",
    "            else:\n",
    "                zz_counter+=1\n",
    "            if zz_counter==2:\n",
    "                break\n",
    "        start_idx=np.nonzero(target_idx)[0][0]\n",
    "        end_idx=np.nonzero(target_idx)[0][-1]\n",
    "        target_start[start_idx]=1\n",
    "        target_end[end_idx]=1\n",
    "        inputs={'input_ids':token_ids,'attention_mask':attention_mask}\n",
    "        outputs={'start_ids':target_start,'end_ids':target_end}\n",
    "        return inputs,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:54.959422Z",
     "iopub.status.busy": "2021-08-31T07:48:54.958764Z",
     "iopub.status.idle": "2021-08-31T07:48:55.098067Z",
     "shell.execute_reply": "2021-08-31T07:48:55.096975Z",
     "shell.execute_reply.started": "2021-08-31T07:48:54.959376Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:55.100214Z",
     "iopub.status.busy": "2021-08-31T07:48:55.099741Z",
     "iopub.status.idle": "2021-08-31T07:48:56.029190Z",
     "shell.execute_reply": "2021-08-31T07:48:56.028198Z",
     "shell.execute_reply.started": "2021-08-31T07:48:55.100169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:56.031359Z",
     "iopub.status.busy": "2021-08-31T07:48:56.030907Z",
     "iopub.status.idle": "2021-08-31T07:48:56.078924Z",
     "shell.execute_reply": "2021-08-31T07:48:56.077938Z",
     "shell.execute_reply.started": "2021-08-31T07:48:56.031319Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(\"textID\",axis=1,inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df=df.reset_index(drop=True)\n",
    "x=df.drop('selected_text',axis=1).values\n",
    "y=df['sentiment'].values\n",
    "skf=StratifiedKFold(n_splits=5)\n",
    "df['kfold']=-1\n",
    "for i,(t,test) in enumerate(skf.split(x,y)):\n",
    "    df.loc[test,'kfold']=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:56.081025Z",
     "iopub.status.busy": "2021-08-31T07:48:56.080497Z",
     "iopub.status.idle": "2021-08-31T07:48:56.105710Z",
     "shell.execute_reply": "2021-08-31T07:48:56.104431Z",
     "shell.execute_reply.started": "2021-08-31T07:48:56.080983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sweet! I`m a Jaycee one-letter-er I think. Ju...</td>\n",
       "      <td>Sweet!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thanks, I`m glad you liked it. It`s a flower ...</td>\n",
       "      <td>Thanks, I`m glad you liked it.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pulled out the breakfast sausage for Mothers D...</td>\n",
       "      <td>Hopefully</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent the Suzaku 7 are back together  woop...</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy Birthday  Hope you enjoyed us singing t...</td>\n",
       "      <td>Happy Birthday</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0   Sweet! I`m a Jaycee one-letter-er I think. Ju...   \n",
       "1   Thanks, I`m glad you liked it. It`s a flower ...   \n",
       "2  Pulled out the breakfast sausage for Mothers D...   \n",
       "3  Excellent the Suzaku 7 are back together  woop...   \n",
       "4   Happy Birthday  Hope you enjoyed us singing t...   \n",
       "\n",
       "                    selected_text sentiment  \n",
       "0                          Sweet!  positive  \n",
       "1  Thanks, I`m glad you liked it.  positive  \n",
       "2                       Hopefully  positive  \n",
       "3                       Excellent  positive  \n",
       "4                  Happy Birthday  positive  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "train=df[df['kfold']!=i].drop('kfold',axis=1).reset_index(drop=True)\n",
    "test=df[df['kfold']==i].drop('kfold',axis=1).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:56.108076Z",
     "iopub.status.busy": "2021-08-31T07:48:56.107605Z",
     "iopub.status.idle": "2021-08-31T07:48:56.118223Z",
     "shell.execute_reply": "2021-08-31T07:48:56.116592Z",
     "shell.execute_reply.started": "2021-08-31T07:48:56.108033Z"
    }
   },
   "outputs": [],
   "source": [
    "text=str(test.iloc[0,0])\n",
    "selected_text=str(test.iloc[0,1])\n",
    "sentiment=str(test.iloc[0,-1])\n",
    "ro_inputs,ro_outputs=get_roberta_data(text,roberta_tokenizer,sentiment,selected_text,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:56.121091Z",
     "iopub.status.busy": "2021-08-31T07:48:56.120301Z",
     "iopub.status.idle": "2021-08-31T07:48:56.144555Z",
     "shell.execute_reply": "2021-08-31T07:48:56.142762Z",
     "shell.execute_reply.started": "2021-08-31T07:48:56.121043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': [0,\n",
       "   939,\n",
       "   12905,\n",
       "   417,\n",
       "   33,\n",
       "   2334,\n",
       "   6,\n",
       "   114,\n",
       "   939,\n",
       "   58,\n",
       "   164,\n",
       "   2,\n",
       "   2,\n",
       "   7974,\n",
       "   2,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  'attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0])},\n",
       " {'start_ids': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'end_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ro_inputs,ro_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:56.148309Z",
     "iopub.status.busy": "2021-08-31T07:48:56.146581Z",
     "iopub.status.idle": "2021-08-31T07:48:56.233561Z",
     "shell.execute_reply": "2021-08-31T07:48:56.232599Z",
     "shell.execute_reply.started": "2021-08-31T07:48:56.147433Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "from tensorflow.keras.layers import Dense,Input,Dropout,Flatten,Softmax,Concatenate,BatchNormalization,TimeDistributed,Conv1D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:56.236803Z",
     "iopub.status.busy": "2021-08-31T07:48:56.236082Z",
     "iopub.status.idle": "2021-08-31T07:48:56.242250Z",
     "shell.execute_reply": "2021-08-31T07:48:56.240719Z",
     "shell.execute_reply.started": "2021-08-31T07:48:56.236761Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "validation_batch_size=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## roberta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:56.244888Z",
     "iopub.status.busy": "2021-08-31T07:48:56.244307Z",
     "iopub.status.idle": "2021-08-31T07:48:56.270901Z",
     "shell.execute_reply": "2021-08-31T07:48:56.269865Z",
     "shell.execute_reply.started": "2021-08-31T07:48:56.244846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1\n",
    "train=df[df['kfold']!=i].drop('kfold',axis=1).reset_index(drop=True)\n",
    "test=df[df['kfold']==i].drop('kfold',axis=1).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:56.272975Z",
     "iopub.status.busy": "2021-08-31T07:48:56.272354Z",
     "iopub.status.idle": "2021-08-31T07:48:56.277921Z",
     "shell.execute_reply": "2021-08-31T07:48:56.276553Z",
     "shell.execute_reply.started": "2021-08-31T07:48:56.272932Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len=110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:48:56.280549Z",
     "iopub.status.busy": "2021-08-31T07:48:56.279827Z",
     "iopub.status.idle": "2021-08-31T07:49:10.416454Z",
     "shell.execute_reply": "2021-08-31T07:49:10.415358Z",
     "shell.execute_reply.started": "2021-08-31T07:48:56.280503Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21984/21984 [00:05<00:00, 3892.26it/s]\n",
      "100%|██████████| 5496/5496 [00:01<00:00, 4140.51it/s]\n"
     ]
    }
   ],
   "source": [
    "model_inputs={'input_ids':np.empty((train.shape[0],max_len),dtype=np.int32),\n",
    "              'attention_mask':np.empty((train.shape[0],max_len),dtype=np.int32)}\n",
    "model_outputs={'start_ids':np.empty((train.shape[0],max_len),dtype=np.int32),\n",
    "               'end_ids':np.empty((train.shape[0],max_len),dtype=np.int32)}\n",
    "############################\n",
    "valid_inputs={'input_ids':np.empty((test.shape[0],max_len),dtype=np.int32),\n",
    "              'attention_mask':np.empty((test.shape[0],max_len),dtype=np.int32)}\n",
    "valid_outputs={'start_ids':np.empty((test.shape[0],max_len),dtype=np.int32),\n",
    "               'end_ids':np.empty((test.shape[0],max_len),dtype=np.int32)}\n",
    "    \n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    inputs,outputs=get_roberta_data(str(train.loc[i,'text']),roberta_tokenizer,str(train.loc[i,'sentiment']),\n",
    "                                    str(train.loc[i,'selected_text']),max_len=max_len)\n",
    "    model_inputs['input_ids'][i,]=inputs['input_ids']\n",
    "    model_inputs['attention_mask'][i,]=inputs['attention_mask']\n",
    "    model_outputs['start_ids'][i,]=outputs['start_ids']\n",
    "    model_outputs['end_ids'][i,]=outputs['end_ids']\n",
    "#############################################\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    inputs,outputs=get_roberta_data(str(test.loc[i,'text']),roberta_tokenizer,str(test.loc[i,'sentiment']),\n",
    "                                    str(test.loc[i,'selected_text']),max_len=max_len)\n",
    "    valid_inputs['input_ids'][i,]=inputs['input_ids']\n",
    "    valid_inputs['attention_mask'][i,]=inputs['attention_mask']\n",
    "    valid_outputs['start_ids'][i,]=outputs['start_ids']\n",
    "    valid_outputs['end_ids'][i,]=outputs['end_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:49:10.420851Z",
     "iopub.status.busy": "2021-08-31T07:49:10.420501Z",
     "iopub.status.idle": "2021-08-31T07:49:10.436604Z",
     "shell.execute_reply": "2021-08-31T07:49:10.435049Z",
     "shell.execute_reply.started": "2021-08-31T07:49:10.420822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': array([[    0,   939, 12905, ...,     1,     1,     1],\n",
       "         [    0,    98,  3036, ...,     1,     1,     1],\n",
       "         [    0,   127,  3504, ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    0,  1423,   857, ...,     1,     1,     1],\n",
       "         [    0,    53,    24, ...,     1,     1,     1],\n",
       "         [    0,    70,    42, ...,     1,     1,     1]], dtype=int32),\n",
       "  'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0]], dtype=int32)},\n",
       " {'start_ids': array([[0, 1, 0, ..., 0, 0, 0],\n",
       "         [0, 1, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 1, 0, ..., 0, 0, 0],\n",
       "         [0, 1, 0, ..., 0, 0, 0],\n",
       "         [0, 1, 0, ..., 0, 0, 0]], dtype=int32),\n",
       "  'end_ids': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int32)})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs,model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:49:10.439089Z",
     "iopub.status.busy": "2021-08-31T07:49:10.438567Z",
     "iopub.status.idle": "2021-08-31T07:49:10.450257Z",
     "shell.execute_reply": "2021-08-31T07:49:10.448632Z",
     "shell.execute_reply.started": "2021-08-31T07:49:10.439045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': array([[    0,  4045,   328, ...,     1,     1,     1],\n",
       "         [    0,  2446,     6, ...,     1,     1,     1],\n",
       "         [    0,  2468,    66, ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    0,  9656,  8974, ...,     1,     1,     1],\n",
       "         [    0, 41437,   116, ...,     1,     1,     1],\n",
       "         [    0,    24, 12905, ...,     1,     1,     1]], dtype=int32),\n",
       "  'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0]], dtype=int32)},\n",
       " {'start_ids': array([[0, 1, 0, ..., 0, 0, 0],\n",
       "         [0, 1, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int32),\n",
       "  'end_ids': array([[0, 1, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int32)})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_inputs,valid_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:49:10.452970Z",
     "iopub.status.busy": "2021-08-31T07:49:10.452248Z",
     "iopub.status.idle": "2021-08-31T07:49:10.459678Z",
     "shell.execute_reply": "2021-08-31T07:49:10.457972Z",
     "shell.execute_reply.started": "2021-08-31T07:49:10.452927Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len=110\n",
    "batch_size=32\n",
    "validation_batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T07:49:10.491866Z",
     "iopub.status.busy": "2021-08-31T07:49:10.491535Z",
     "iopub.status.idle": "2021-08-31T07:49:10.505352Z",
     "shell.execute_reply": "2021-08-31T07:49:10.503895Z",
     "shell.execute_reply.started": "2021-08-31T07:49:10.491836Z"
    }
   },
   "outputs": [],
   "source": [
    "def MODEL():\n",
    "    tf.keras.backend.clear_session()\n",
    "    roberta_model=TFRobertaModel.from_pretrained('roberta-base')\n",
    "    ins1=Input((110,),dtype=tf.int32,name='input_ids')\n",
    "    ins2=Input((110,),dtype=tf.int32,name='attention_mask')\n",
    "    pre_layers=roberta_model({'input_ids':ins1,'attention_mask':ins2})\n",
    "    drop=Dropout(0.1)(pre_layers[0])\n",
    "    d=Conv1D(2,1)(drop)\n",
    "    x1,x2=tf.keras.layers.Lambda(lambda a:tf.split(a,2,axis=-1))(d)\n",
    "    x1=Flatten()(x1)\n",
    "    out1=Softmax(name='start_ids')(x1)\n",
    "    x2=Flatten()(x2)\n",
    "    out2=Softmax(name='end_ids')(x2)\n",
    "    model=Model(inputs={'input_ids':ins1,'attention_mask':ins2},\n",
    "           outputs={'start_ids':out1,'end_ids':out2})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f73546e882449bbc9e17541281882e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94402d157d9a4254b15a56223a10e7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/657M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f522c19f360>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f522c19f360>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "model=MODEL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attention_mask (InputLayer)     [(None, 110)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ids (InputLayer)          [(None, 110)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   attention_mask[0][0]             \n",
      "                                                                 input_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 110, 768)     0           tf_roberta_model[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 110, 2)       1538        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 [(None, 110, 1), (No 0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 110)          0           lambda[0][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 110)          0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "end_ids (Softmax)               (None, 110)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "start_ids (Softmax)             (None, 110)          0           flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 124,647,170\n",
      "Trainable params: 124,647,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38813"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T11:10:23.885773Z",
     "iopub.status.busy": "2021-08-31T11:10:23.885422Z",
     "iopub.status.idle": "2021-08-31T13:32:24.326241Z",
     "shell.execute_reply": "2021-08-31T13:32:24.325220Z",
     "shell.execute_reply.started": "2021-08-31T11:10:23.885741Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21984/21984 [00:08<00:00, 2514.78it/s]\n",
      "100%|██████████| 5496/5496 [00:01<00:00, 2967.85it/s]\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "687/687 [==============================] - ETA: 0s - loss: 2.6755 - end_ids_loss: 1.3225 - start_ids_loss: 1.3530WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - 716s 762ms/step - loss: 2.6747 - end_ids_loss: 1.3221 - start_ids_loss: 1.3526 - val_loss: 1.6130 - val_end_ids_loss: 0.7598 - val_start_ids_loss: 0.8532\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61299, saving model to roberta_stratified_conv_split_0.h5\n",
      "Epoch 2/10\n",
      "687/687 [==============================] - 550s 801ms/step - loss: 1.5811 - end_ids_loss: 0.7520 - start_ids_loss: 0.8292 - val_loss: 1.5825 - val_end_ids_loss: 0.7522 - val_start_ids_loss: 0.8303\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.61299 to 1.58245, saving model to roberta_stratified_conv_split_0.h5\n",
      "Epoch 3/10\n",
      "687/687 [==============================] - 549s 800ms/step - loss: 1.4013 - end_ids_loss: 0.6697 - start_ids_loss: 0.7316 - val_loss: 1.5894 - val_end_ids_loss: 0.7609 - val_start_ids_loss: 0.8285\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.58245\n",
      "Epoch 4/10\n",
      "687/687 [==============================] - 550s 801ms/step - loss: 1.2581 - end_ids_loss: 0.5901 - start_ids_loss: 0.6680 - val_loss: 1.6896 - val_end_ids_loss: 0.8121 - val_start_ids_loss: 0.8774\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.58245\n",
      "Epoch 5/10\n",
      "687/687 [==============================] - 550s 801ms/step - loss: 1.0889 - end_ids_loss: 0.5052 - start_ids_loss: 0.5838 - val_loss: 1.7836 - val_end_ids_loss: 0.8301 - val_start_ids_loss: 0.9535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/21984 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve from 1.58245\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21984/21984 [00:05<00:00, 3856.79it/s]\n",
      "100%|██████████| 5496/5496 [00:01<00:00, 3910.30it/s]\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "687/687 [==============================] - ETA: 0s - loss: 2.6412 - end_ids_loss: 1.3041 - start_ids_loss: 1.3371WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - 559s 802ms/step - loss: 2.6403 - end_ids_loss: 1.3037 - start_ids_loss: 1.3366 - val_loss: 1.6130 - val_end_ids_loss: 0.7815 - val_start_ids_loss: 0.8315\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61302, saving model to roberta_stratified_conv_split_1.h5\n",
      "Epoch 2/10\n",
      "687/687 [==============================] - 550s 801ms/step - loss: 1.6239 - end_ids_loss: 0.7673 - start_ids_loss: 0.8565 - val_loss: 1.5602 - val_end_ids_loss: 0.7529 - val_start_ids_loss: 0.8073\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.61302 to 1.56021, saving model to roberta_stratified_conv_split_1.h5\n",
      "Epoch 3/10\n",
      "687/687 [==============================] - 549s 799ms/step - loss: 1.3871 - end_ids_loss: 0.6466 - start_ids_loss: 0.7405 - val_loss: 1.5897 - val_end_ids_loss: 0.7561 - val_start_ids_loss: 0.8336\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.56021\n",
      "Epoch 4/10\n",
      "687/687 [==============================] - 551s 801ms/step - loss: 1.2660 - end_ids_loss: 0.5913 - start_ids_loss: 0.6746 - val_loss: 1.6158 - val_end_ids_loss: 0.7838 - val_start_ids_loss: 0.8320\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.56021\n",
      "Epoch 5/10\n",
      "687/687 [==============================] - 550s 801ms/step - loss: 1.0817 - end_ids_loss: 0.4985 - start_ids_loss: 0.5832 - val_loss: 1.7611 - val_end_ids_loss: 0.8691 - val_start_ids_loss: 0.8920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/21984 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve from 1.56021\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21984/21984 [00:05<00:00, 3913.46it/s]\n",
      "100%|██████████| 5496/5496 [00:01<00:00, 3912.82it/s]\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "687/687 [==============================] - ETA: 0s - loss: 2.8178 - end_ids_loss: 1.3498 - start_ids_loss: 1.4679WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - 559s 802ms/step - loss: 2.8168 - end_ids_loss: 1.3494 - start_ids_loss: 1.4674 - val_loss: 1.6282 - val_end_ids_loss: 0.7633 - val_start_ids_loss: 0.8649\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.62820, saving model to roberta_stratified_conv_split_2.h5\n",
      "Epoch 2/10\n",
      "687/687 [==============================] - 550s 801ms/step - loss: 1.6022 - end_ids_loss: 0.7629 - start_ids_loss: 0.8393 - val_loss: 1.5944 - val_end_ids_loss: 0.7475 - val_start_ids_loss: 0.8469\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.62820 to 1.59440, saving model to roberta_stratified_conv_split_2.h5\n",
      "Epoch 3/10\n",
      "687/687 [==============================] - 550s 801ms/step - loss: 1.4122 - end_ids_loss: 0.6742 - start_ids_loss: 0.7380 - val_loss: 1.5973 - val_end_ids_loss: 0.7584 - val_start_ids_loss: 0.8389\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.59440\n",
      "Epoch 4/10\n",
      "687/687 [==============================] - 550s 801ms/step - loss: 1.2768 - end_ids_loss: 0.5972 - start_ids_loss: 0.6796 - val_loss: 1.6129 - val_end_ids_loss: 0.7611 - val_start_ids_loss: 0.8518\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.59440\n",
      "Epoch 5/10\n",
      "687/687 [==============================] - 550s 801ms/step - loss: 1.1106 - end_ids_loss: 0.5139 - start_ids_loss: 0.5967 - val_loss: 1.8238 - val_end_ids_loss: 0.8700 - val_start_ids_loss: 0.9538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/21984 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve from 1.59440\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21984/21984 [00:05<00:00, 3885.14it/s]\n",
      "100%|██████████| 5496/5496 [00:01<00:00, 3971.38it/s]\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "687/687 [==============================] - ETA: 0s - loss: 2.6436 - end_ids_loss: 1.3211 - start_ids_loss: 1.3225WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - 559s 802ms/step - loss: 2.6427 - end_ids_loss: 1.3206 - start_ids_loss: 1.3221 - val_loss: 1.5739 - val_end_ids_loss: 0.7480 - val_start_ids_loss: 0.8259\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.57389, saving model to roberta_stratified_conv_split_3.h5\n",
      "Epoch 2/10\n",
      "687/687 [==============================] - 550s 801ms/step - loss: 1.5603 - end_ids_loss: 0.7461 - start_ids_loss: 0.8142 - val_loss: 1.5476 - val_end_ids_loss: 0.7310 - val_start_ids_loss: 0.8165\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.57389 to 1.54756, saving model to roberta_stratified_conv_split_3.h5\n",
      "Epoch 3/10\n",
      "687/687 [==============================] - 550s 801ms/step - loss: 1.3536 - end_ids_loss: 0.6303 - start_ids_loss: 0.7233 - val_loss: 1.6170 - val_end_ids_loss: 0.7767 - val_start_ids_loss: 0.8404\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.54756\n",
      "Epoch 4/10\n",
      "687/687 [==============================] - 550s 801ms/step - loss: 1.1981 - end_ids_loss: 0.5497 - start_ids_loss: 0.6485 - val_loss: 1.6905 - val_end_ids_loss: 0.8008 - val_start_ids_loss: 0.8897\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.54756\n",
      "Epoch 5/10\n",
      "687/687 [==============================] - 550s 801ms/step - loss: 1.1325 - end_ids_loss: 0.5331 - start_ids_loss: 0.5994 - val_loss: 1.8125 - val_end_ids_loss: 0.8607 - val_start_ids_loss: 0.9518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/21984 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve from 1.54756\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21984/21984 [00:05<00:00, 3769.48it/s]\n",
      "100%|██████████| 5496/5496 [00:01<00:00, 3885.89it/s]\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "687/687 [==============================] - ETA: 0s - loss: 2.7503 - end_ids_loss: 1.3738 - start_ids_loss: 1.3765WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - 559s 802ms/step - loss: 2.7494 - end_ids_loss: 1.3733 - start_ids_loss: 1.3760 - val_loss: 1.6301 - val_end_ids_loss: 0.7790 - val_start_ids_loss: 0.8511\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.63012, saving model to roberta_stratified_conv_split_4.h5\n",
      "Epoch 2/10\n",
      "687/687 [==============================] - 551s 802ms/step - loss: 1.5860 - end_ids_loss: 0.7457 - start_ids_loss: 0.8403 - val_loss: 1.5906 - val_end_ids_loss: 0.7539 - val_start_ids_loss: 0.8367\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.63012 to 1.59056, saving model to roberta_stratified_conv_split_4.h5\n",
      "Epoch 3/10\n",
      "687/687 [==============================] - 551s 802ms/step - loss: 1.4059 - end_ids_loss: 0.6629 - start_ids_loss: 0.7430 - val_loss: 1.6303 - val_end_ids_loss: 0.7764 - val_start_ids_loss: 0.8539\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.59056\n",
      "Epoch 4/10\n",
      "687/687 [==============================] - 551s 802ms/step - loss: 1.2863 - end_ids_loss: 0.5957 - start_ids_loss: 0.6907 - val_loss: 1.6793 - val_end_ids_loss: 0.8163 - val_start_ids_loss: 0.8630\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.59056\n",
      "Epoch 5/10\n",
      "687/687 [==============================] - 551s 801ms/step - loss: 1.1060 - end_ids_loss: 0.5231 - start_ids_loss: 0.5829 - val_loss: 1.6631 - val_end_ids_loss: 0.8134 - val_start_ids_loss: 0.8497\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.59056\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    train=df[df['kfold']!=j].drop('kfold',axis=1).reset_index(drop=True)\n",
    "    test=df[df['kfold']==j].drop('kfold',axis=1).reset_index(drop=True)\n",
    "    max_len=110\n",
    "    model_inputs={'input_ids':np.empty((train.shape[0],max_len),dtype=np.int32),\n",
    "                  'attention_mask':np.empty((train.shape[0],max_len),dtype=np.int32)}\n",
    "    model_outputs={'start_ids':np.empty((train.shape[0],max_len),dtype=np.int32),\n",
    "                   'end_ids':np.empty((train.shape[0],max_len),dtype=np.int32)}\n",
    "    ############################\n",
    "    valid_inputs={'input_ids':np.empty((test.shape[0],max_len),dtype=np.int32),\n",
    "                  'attention_mask':np.empty((test.shape[0],max_len),dtype=np.int32)}\n",
    "    valid_outputs={'start_ids':np.empty((test.shape[0],max_len),dtype=np.int32),\n",
    "                   'end_ids':np.empty((test.shape[0],max_len),dtype=np.int32)}\n",
    "        \n",
    "    for i in tqdm(range(train.shape[0])):\n",
    "        inputs,outputs=get_roberta_data(str(train.loc[i,'text']),roberta_tokenizer,str(train.loc[i,'sentiment']),\n",
    "                                        str(train.loc[i,'selected_text']),max_len=max_len)\n",
    "        model_inputs['input_ids'][i,]=inputs['input_ids']\n",
    "        model_inputs['attention_mask'][i,]=inputs['attention_mask']\n",
    "        model_outputs['start_ids'][i,]=outputs['start_ids']\n",
    "        model_outputs['end_ids'][i,]=outputs['end_ids']\n",
    "    #############################################\n",
    "    for i in tqdm(range(test.shape[0])):\n",
    "        inputs,outputs=get_roberta_data(str(test.loc[i,'text']),roberta_tokenizer,str(test.loc[i,'sentiment']),\n",
    "                                        str(test.loc[i,'selected_text']),max_len=max_len)\n",
    "        valid_inputs['input_ids'][i,]=inputs['input_ids']\n",
    "        valid_inputs['attention_mask'][i,]=inputs['attention_mask']\n",
    "        valid_outputs['start_ids'][i,]=outputs['start_ids']\n",
    "        valid_outputs['end_ids'][i,]=outputs['end_ids']\n",
    "    batch_size=32\n",
    "    validation_batch_size=16\n",
    "    model=MODEL()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),loss='categorical_crossentropy')\n",
    "    saver=tf.keras.callbacks.ModelCheckpoint(filepath=f'roberta_stratified_conv_split_{j}.h5',save_weights_only=True,\n",
    "                                            save_best_only=True,save_freq='epoch',verbose=1,monitor='val_loss',mode='min')\n",
    "    stopper=tf.keras.callbacks.EarlyStopping(verbose=1,monitor='val_loss',mode='min',patience=3)\n",
    "    model.fit(model_inputs,model_outputs,epochs=10,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(valid_inputs,valid_outputs),\n",
    "              validation_batch_size=validation_batch_size,\n",
    "             callbacks=[saver,stopper])\n",
    "    del model\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T13:34:01.597174Z",
     "iopub.status.busy": "2021-08-31T13:34:01.596718Z",
     "iopub.status.idle": "2021-08-31T13:34:01.604923Z",
     "shell.execute_reply": "2021-08-31T13:34:01.603549Z",
     "shell.execute_reply.started": "2021-08-31T13:34:01.597140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.575036"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.58245+1.56021+1.59440+1.54756+1.59056)/5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  kfold  \n",
       "0  I`d have responded, if I were going   neutral      0  \n",
       "1                             Sooo SAD  negative      0  \n",
       "2                          bullying me  negative      0  \n",
       "3                       leave me alone  negative      0  \n",
       "4                        Sons of ****,  negative      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment']=df['sentiment'].map({'neutral':0,'positive':1,'negative':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text  sentiment  kfold  \n",
       "0  I`d have responded, if I were going          0      0  \n",
       "1                             Sooo SAD          2      0  \n",
       "2                          bullying me          2      0  \n",
       "3                       leave me alone          2      0  \n",
       "4                        Sons of ****,          2      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MODEL():\n",
    "    tf.keras.backend.clear_session()\n",
    "    roberta_model=TFRobertaModel.from_pretrained('roberta-base')\n",
    "    ins1=Input((110,),dtype=tf.int32,name='input_ids')\n",
    "    ins2=Input((110,),dtype=tf.int32,name='attention_mask')\n",
    "    pre_layers=roberta_model({'input_ids':ins1,'attention_mask':ins2})\n",
    "    drop=Dropout(0.1)(pre_layers[1])\n",
    "    outs=Dense(3,activation='softmax')(drop)\n",
    "    model=Model(inputs={'input_ids':ins1,'attention_mask':ins2},\n",
    "           outputs=outs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f3978826360>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f3978826360>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attention_mask (InputLayer)     [(None, 110)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ids (InputLayer)          [(None, 110)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   attention_mask[0][0]             \n",
      "                                                                 input_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 768)          0           tf_roberta_model[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            2307        dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 124,647,939\n",
      "Trainable params: 124,647,939\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=MODEL()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_data(tweet,max_len):\n",
    "    tokens=roberta_tokenizer.encode(' '+tweet).tokens\n",
    "    input_ids=roberta_tokenizer.encode(' '+tweet).ids\n",
    "    if len(tokens)>(max_len-2):\n",
    "        tokens=['<s>']+tokens[:(max_len-2)]+['</s>']\n",
    "        input_ids=[0]+input_ids[:(max_len-2)]+[2]\n",
    "    else:\n",
    "        pad_length=max_len-len(tokens)-2\n",
    "        tokens=['<s>']+tokens+['</s>']+['<pad>']*pad_length\n",
    "        input_ids=[0]+input_ids+[2]+[1]*pad_length\n",
    "    attention_mask=np.char.not_equal('<pad>',tokens).astype('int')\n",
    "    return {'input_ids':input_ids,\n",
    "            'attention_mask':attention_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21984/21984 [00:03<00:00, 5666.08it/s]\n",
      "100%|██████████| 5496/5496 [00:00<00:00, 5699.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train=df[df['kfold']!=j].drop('kfold',axis=1).reset_index(drop=True)\n",
    "test=df[df['kfold']==j].drop('kfold',axis=1).reset_index(drop=True)\n",
    "max_len=110\n",
    "model_inputs={'input_ids':np.empty((train.shape[0],max_len),dtype=np.int32),\n",
    "              'attention_mask':np.empty((train.shape[0],max_len),dtype=np.int32)\n",
    "             }\n",
    "model_outputs=np.empty((train.shape[0],),dtype=np.int32)\n",
    "############################\n",
    "valid_inputs={'input_ids':np.empty((test.shape[0],max_len),dtype=np.int32),\n",
    "              'attention_mask':np.empty((test.shape[0],max_len),dtype=np.int32)}\n",
    "valid_outputs=np.empty((test.shape[0],),dtype=np.int32)\n",
    "    \n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    inputs,outputs=get_sentiment_data(str(train.loc[i,'text']),max_len=max_len),int(train.loc[i,'sentiment'])\n",
    "    model_inputs['input_ids'][i,]=inputs['input_ids']\n",
    "    model_inputs['attention_mask'][i,]=inputs['attention_mask']\n",
    "    model_outputs[i,]=outputs\n",
    "#############################################\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    inputs,outputs=get_sentiment_data(str(test.loc[i,'text']),max_len=max_len),int(test.loc[i,'sentiment'])\n",
    "    valid_inputs['input_ids'][i,]=inputs['input_ids']\n",
    "    valid_inputs['attention_mask'][i,]=inputs['attention_mask']\n",
    "    valid_outputs[i,]=outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': array([[   0, 1437, 4045, ...,    1,    1,    1],\n",
       "         [   0, 1437, 2446, ...,    1,    1,    1],\n",
       "         [   0, 2468,   66, ...,    1,    1,    1],\n",
       "         ...,\n",
       "         [   0, 1437, 1423, ...,    1,    1,    1],\n",
       "         [   0, 1437,   53, ...,    1,    1,    1],\n",
       "         [   0, 1437, 1437, ...,    1,    1,    1]], dtype=int32),\n",
       "  'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0]], dtype=int32)},\n",
       " array([1, 1, 1, ..., 1, 1, 0], dtype=int32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs,model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,  1437,  4045,   328,   939, 12905,   119,    10,  1236,\n",
       "         857,  1755,   242,    65,    12, 36419,    12,   254,   939,\n",
       "         206,     4,    95,   385,   328,     2,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['attention_mask'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': array([[   0, 1437,  939, ...,    1,    1,    1],\n",
       "         [   0, 1437,   98, ...,    1,    1,    1],\n",
       "         [   0,  127, 3504, ...,    1,    1,    1],\n",
       "         ...,\n",
       "         [   0, 1437,   16, ...,    1,    1,    1],\n",
       "         [   0, 6661,    7, ...,    1,    1,    1],\n",
       "         [   0,  939,  222, ...,    1,    1,    1]], dtype=int32),\n",
       "  'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 0, 0, 0]], dtype=int32)},\n",
       " array([0, 2, 2, ..., 2, 2, 2], dtype=int32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_inputs,valid_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27236"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model_inputs,model_outputs,valid_inputs,valid_outputs,j,train,test\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21984/21984 [00:04<00:00, 5044.38it/s]\n",
      "100%|██████████| 5496/5496 [00:01<00:00, 5033.01it/s]\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - ETA: 0s - loss: 0.7110WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - 516s 741ms/step - loss: 0.7108 - val_loss: 0.5286\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52862, saving model to sentiment_model_0.h5\n",
      "Epoch 2/10\n",
      "687/687 [==============================] - 518s 754ms/step - loss: 0.4631 - val_loss: 0.5105\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52862 to 0.51054, saving model to sentiment_model_0.h5\n",
      "Epoch 3/10\n",
      "687/687 [==============================] - 510s 743ms/step - loss: 0.3721 - val_loss: 0.5215\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.51054\n",
      "Epoch 4/10\n",
      "687/687 [==============================] - 512s 745ms/step - loss: 0.3096 - val_loss: 0.6285\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.51054\n",
      "Epoch 5/10\n",
      "687/687 [==============================] - 517s 752ms/step - loss: 0.2387 - val_loss: 0.6963\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.51054\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21984/21984 [00:04<00:00, 5096.16it/s]\n",
      "100%|██████████| 5496/5496 [00:00<00:00, 5515.10it/s]\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - ETA: 0s - loss: 0.7030WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - 527s 757ms/step - loss: 0.7029 - val_loss: 0.5171\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51705, saving model to sentiment_model_1.h5\n",
      "Epoch 2/10\n",
      "687/687 [==============================] - 518s 754ms/step - loss: 0.4550 - val_loss: 0.5435\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.51705\n",
      "Epoch 3/10\n",
      "687/687 [==============================] - 518s 754ms/step - loss: 0.3778 - val_loss: 0.5444\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.51705\n",
      "Epoch 4/10\n",
      "687/687 [==============================] - 518s 754ms/step - loss: 0.3023 - val_loss: 0.5796\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.51705\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21984/21984 [00:04<00:00, 5046.39it/s]\n",
      "100%|██████████| 5496/5496 [00:01<00:00, 4952.85it/s]\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - ETA: 0s - loss: 0.7137WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - 527s 757ms/step - loss: 0.7135 - val_loss: 0.5345\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.53448, saving model to sentiment_model_2.h5\n",
      "Epoch 2/10\n",
      "687/687 [==============================] - 518s 754ms/step - loss: 0.4754 - val_loss: 0.5611\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.53448\n",
      "Epoch 3/10\n",
      "687/687 [==============================] - 517s 753ms/step - loss: 0.3791 - val_loss: 0.5467\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.53448\n",
      "Epoch 4/10\n",
      "687/687 [==============================] - 517s 753ms/step - loss: 0.3064 - val_loss: 0.5819\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.53448\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21984/21984 [00:04<00:00, 4981.69it/s]\n",
      "100%|██████████| 5496/5496 [00:01<00:00, 4878.34it/s]\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - ETA: 0s - loss: 0.6956WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - 526s 756ms/step - loss: 0.6955 - val_loss: 0.5020\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50204, saving model to sentiment_model_3.h5\n",
      "Epoch 2/10\n",
      "687/687 [==============================] - 518s 754ms/step - loss: 0.4626 - val_loss: 0.5436\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.50204\n",
      "Epoch 3/10\n",
      "687/687 [==============================] - 518s 754ms/step - loss: 0.3741 - val_loss: 0.5181\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.50204\n",
      "Epoch 4/10\n",
      "687/687 [==============================] - 518s 755ms/step - loss: 0.2909 - val_loss: 0.5787\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.50204\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21984/21984 [00:04<00:00, 5074.40it/s]\n",
      "100%|██████████| 5496/5496 [00:01<00:00, 5142.57it/s]\n",
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - ETA: 0s - loss: 0.7143WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "687/687 [==============================] - 528s 758ms/step - loss: 0.7142 - val_loss: 0.5410\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.54096, saving model to sentiment_model_4.h5\n",
      "Epoch 2/10\n",
      "687/687 [==============================] - 518s 755ms/step - loss: 0.4652 - val_loss: 0.5150\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.54096 to 0.51498, saving model to sentiment_model_4.h5\n",
      "Epoch 3/10\n",
      "687/687 [==============================] - 518s 755ms/step - loss: 0.3797 - val_loss: 0.5296\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.51498\n",
      "Epoch 4/10\n",
      "687/687 [==============================] - 519s 755ms/step - loss: 0.2900 - val_loss: 0.6295\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.51498\n",
      "Epoch 5/10\n",
      "687/687 [==============================] - 519s 755ms/step - loss: 0.2218 - val_loss: 0.6772\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.51498\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    train=df[df['kfold']!=j].drop('kfold',axis=1).reset_index(drop=True)\n",
    "    test=df[df['kfold']==j].drop('kfold',axis=1).reset_index(drop=True)\n",
    "    max_len=110\n",
    "    model_inputs={'input_ids':np.empty((train.shape[0],max_len),dtype=np.int32),\n",
    "                  'attention_mask':np.empty((train.shape[0],max_len),dtype=np.int32)\n",
    "                 }\n",
    "    model_outputs=np.empty((train.shape[0],3),dtype=np.int32)\n",
    "    ############################\n",
    "    valid_inputs={'input_ids':np.empty((test.shape[0],max_len),dtype=np.int32),\n",
    "                  'attention_mask':np.empty((test.shape[0],max_len),dtype=np.int32)}\n",
    "    valid_outputs=np.empty((test.shape[0],3),dtype=np.int32)\n",
    "    for i in tqdm(range(train.shape[0])):\n",
    "        inputs,outputs=get_sentiment_data(str(train.loc[i,'text']),max_len=max_len),int(train.loc[i,'sentiment'])\n",
    "        model_inputs['input_ids'][i,]=inputs['input_ids']\n",
    "        model_inputs['attention_mask'][i,]=inputs['attention_mask']\n",
    "        model_outputs[i,]=tf.keras.utils.to_categorical(outputs,num_classes=3)\n",
    "    #############################################\n",
    "    for i in tqdm(range(test.shape[0])):\n",
    "        inputs,outputs=get_sentiment_data(str(test.loc[i,'text']),max_len=max_len),int(test.loc[i,'sentiment'])\n",
    "        valid_inputs['input_ids'][i,]=inputs['input_ids']\n",
    "        valid_inputs['attention_mask'][i,]=inputs['attention_mask']\n",
    "        valid_outputs[i,]=tf.keras.utils.to_categorical(outputs,num_classes=3)\n",
    "    batch_size=32\n",
    "    validation_batch_size=16\n",
    "    model=MODEL()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),loss='categorical_crossentropy')\n",
    "    saver=tf.keras.callbacks.ModelCheckpoint(filepath=f'sentiment_model_{j}.h5',save_weights_only=True,\n",
    "                                            save_best_only=True,save_freq='epoch',verbose=1,monitor='val_loss',mode='min')\n",
    "    stopper=tf.keras.callbacks.EarlyStopping(verbose=1,monitor='val_loss',mode='min',patience=3)\n",
    "    model.fit(model_inputs,model_outputs,epochs=10,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(valid_inputs,valid_outputs),\n",
    "              validation_batch_size=validation_batch_size,\n",
    "             callbacks=[saver,stopper])\n",
    "    del model\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.515818"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.51054+0.51705+0.53448+0.50204+0.51498)/5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
